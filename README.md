# Deep Learning for Visual Intelligence: Trends and Challenges 

## Course information

* Instructor: WANG Lin (linwang@ust.hk)
* TAs: SU Ying (ysuay@connect.ust.hk) and ZHU Qingyan (qzhuai@connect.ust.hk)
* Office Hours: BY appointment only.

## Grading policy 
- Paper summary (10%)
- Paper presentation and discussion (30%)
- Group project and paper submission (50%)
- Attendance and Participation (10%)

##  Tentative schedule
| Dates | Topics | Active Learning |
| --- | --- | --- |
| 2/8 | Course introduction | |
| 2/10 | Course introduction | Overview of computer vision |
| 2/15 | Deep learning basics | TAs’ lectures for CNN basics, algorithm basics and Pytorch tuorial  |
| 2/17 | Deep learning basics | TAs’ lectures for CNN basics, algorithm basics and Pytorch tuorial  |
| 2/22 | DNN models in computer vision (GAN, RNN, GNN) |   |
| 2/24 | DNN models in computer vision (GAN, RNN, GNN) |  (1) Persenation (2) Review due 2/27 (3) Project meetings |
| 3/1 | Learning methods in computer vision (Transfer learning, domain adaptation, self/semi-supervised learning) |   |
| 3/3 | Learning methods in computer vision ((Transfer learning, domain adaptation, self/semi-supervised learning)) |  (1) Persenation (2) Review due 3/6  |
| 3/8 |Deep learning for image restoration and enhancement (I) deblurring, deraining, dehazing |   |
| 3/10 |Deep learning for image restoration and enhancement (I) deblurring, deraining, dehazing  |  (1) Persenation (2) Review due 3/13 (3) Project proposal kick-off (one page) |
| 3/15 |Deep learning for image restoration and enhancement (II) Super-resolution, HDR imaging |   |
| 3/17 |Deep learning for image restoration and enhancement (II) Super-resolution, HDR imaging  |  (1) Persenation (2) Review due 3/20 |
| 3/22 |Deep learning for scene understanding (I) Object detection & tracking |  |
| 3/24 |Deep learning for scene understanding (I) Object detection & tracking | Project mid-term presentation |
| 3/29 |Deep learning for scene understanding (II) Semantic segmentation  |  |
| 3/31 |Deep learning for scene understanding (II) Semantic segmentation  | (1) Persenation (2) Review due 4/3 |
| 4/5 |Computer vision with novel cameras (I) Event camera-based vision  |  |
| 4/7 |Computer vision with novel cameras (I) Event camera-based vision  | (1) Persenation (2) Review due 4/10 |
| 4/12 |Computer vision with novel cameras (II) Thermal/360 camera-based vision  |  |
| 4/14 |Computer vision with novel cameras (II) Thermal/360 camera-based vision  | (1) Persenation (2) Review due 4/17 (3) Project meetings |
| 4/19 |Special vision problems (Learning  in adverse visual conditions) |  |
| 4/21 |Special vision problems (Learning  in adverse visual conditions) | (1) Persenation (2) Review due 4/24 |
| 4/26 |Adversarial robustness in computer vision (Adversrial attack and defense) |  |
| 4/28 |Adversarial robustness in computer vision (Adversrial attack and defense)| (1) Persenation (2) Review due 4/31 (3) Project meetings |
| 5/3 |Potential and Challenges in computer vision (data, computation, learning, sensor) (self-driving and robotics) |  |
| 5/5 |Potential and Challenges in computer vision (data, computation, learning, sensor) (self-driving and robotics)| (1) TA/Student lectures (2) final project Q/A  |
| 5/10 |Project presentation and final paper submission |  |
| 5/12 |Project presentation and final paper submission | Submission due 5/26  |


##  Reading list

### DNN models in computer vision (VAEs, GANs, RNNs)
#### VAEs
[[Kingma and Welling 14]](https://arxiv.org/pdf/1312.6114v10.pdf) Auto-Encoding Variational Bayes, ICLR 2014. </br>
[[Kingma et al. 15]](https://arxiv.org/pdf/1506.02557.pdf) Variational Dropout and the Local Reparameterization Trick, NIPS 2015.</br>
[[Blundell et al. 15]](https://arxiv.org/pdf/1505.05424.pdf) Weight Uncertainty in Neural Networks, ICML 2015.</br>
[[Gal and Ghahramani 16]](http://proceedings.mlr.press/v48/gal16.pdf) Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning, ICML 2016. </br>

#### GANs
[Goodfellow et al. 14] Generative Adversarial Nets, NIPS 2014. </br>
[Radford et al. 15] Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, ICLR 2016. </br>
[Chen et al. 16] InfoGAN: Interpreting Representation Learning by Information Maximizing Generative Adversarial Nets, NIPS 2016. </br>
[Arjovsky et al. 17] Wasserstein Generative Adversarial Networks, ICML 2017. </br>
[Zhu et al. 17] Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, ICCV 2017.</br>
[Karras et al. 18] Progressive Growing of GANs for Improved Quality, Stability, and Variation, ICLR 2018. </br>
[Choi et al. 18] StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation, CVPR 2018.  </br>
[Brock et al. 19] Large Scale GAN Training for High-Fidelity Natural Image Synthesis, ICLR 2019. </br>
[Karras et al. 19] A Style-Based Generator Architecture for Generative Adversarial Networks, CVPR 2019. </br>
[Karras et al. 20] Analyzing and Improving the Image Quality of StyleGAN, CVPR 2020. </br>
[Sinha et al. 20] Small-GAN: Speeding up GAN Training using Core-Sets, ICML 2020. </br> 
[Karras et al. 20] Training Generative Adversarial Networks with Limited Data, NeurIPS 2020. </br> 
[Liu et al. 21] Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis, ICLR 2021. </br>
[Hudson and Zitnick 21] Generative Adversarial Transformers, ICML 2021. </br>
[Karras et al. 21] Alias-Free GAN, arXiv preprint, 2021.  </br>
 
#### RNNs


